# 🗑️ EcoSort AI 智能垃圾分类系统使用说明书

## 1. 系统简介
本系统基于 **React (前端)** + **FastAPI (后端)** + **MobileNetV3 (本地AI模型)** 构建，旨在提供快速、准确的垃圾分类识别服务。

### 核心功能
*   **拍照/上传识别**：支持图片上传或直接调用摄像头拍照。
*   **本地离线推理**：内置轻量级 MobileNetV3 模型，无需联网即可识别 12 类常见垃圾。
*   **云端增强识别**：集成阿里云 Qwen-VL 大模型，处理复杂场景（需配置 API Key）。
*   **分类百科**：提供详细的垃圾分类建议（可回收、有害、厨余、其他）。

---

## 2. 数据集下载与配置

本项目使用 **Garbage Classification (12 classes)** 数据集进行训练。

### 2.1 数据集简介
包含 12 个常见垃圾类别：
- **可回收物**: Cardboard (纸板), Glass (玻璃), Metal (金属), Paper (纸张), Plastic (塑料), Clothes (衣物), Shoes (鞋子), Wood (木材)
- **有害垃圾**: Battery (电池)
- **湿垃圾**: Food Waste (厨余)
- **干垃圾**: Trash (其他), Ceramic (陶瓷)

### 2.2 下载与配置
1.  **下载**: 请访问 Kaggle 下载 [Garbage Classification (12 classes)](https://www.kaggle.com/datasets/mostafaabla/garbage-classification)。
2.  **解压**: 将数据解压至 `app/backend-python/data` 目录。
3.  **划分**: 运行 `python training/prepare_data.py split` 自动划分训练集和验证集。

---

## 3. 环境搭建与配置

### 3.1 前端环境 (Node.js)
1.  **安装 Node.js**: 请访问 [Node.js 官网](https://nodejs.org/) 下载并安装 LTS 版本 (v16 或更高)。
2.  **安装依赖**:
    打开终端，进入 `app` 目录并运行：
    ```bash
    cd app
    npm install
    ```

### 3.2 后端环境 (Python)
推荐使用 Anaconda 管理 Python 环境。

1.  **安装 Anaconda**: 请访问 [Anaconda 官网](https://www.anaconda.com/) 下载安装。
2.  **创建虚拟环境**:
    打开终端 (Anaconda Prompt)，运行以下命令创建名为 `trash` 的环境：
    ```bash
    conda create -n trash python=3.9
    ```
3.  **激活环境**:
    ```bash
    conda activate trash
    ```
4.  **安装依赖库**:
    进入 `app/backend-python` 目录，安装项目所需库：
    ```bash
    cd app/backend-python
    pip install -r requirements.txt
    ```
    *   *注意*: 如果您有 NVIDIA 显卡，建议单独安装 PyTorch GPU 版以获得更快的训练速度：
        ```bash
        pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
        ```

---

## 4. 快速启动

### 4.1 启动后端服务
后端负责处理图片识别请求和数据库交互。

1.  打开终端（CMD 或 PowerShell）。
2.  进入后端目录：
    ```bash
    cd app/backend-python
    ```
3.  激活 Python 环境（如果有）：
    ```bash
    conda activate trash  # 示例
    ```
4.  启动服务：
    ```bash
    python main.py
    ```
    *   成功后会显示：`Uvicorn running on http://0.0.0.0:8000`

### 4.2 启动前端界面
前端提供用户交互界面。

1.  打开一个新的终端窗口。
2.  进入应用根目录：
    ```bash
    cd app
    ```
3.  启动开发服务器：
    ```bash
    npm run dev
    ```
4.  浏览器会自动打开 `http://localhost:5173`，即可开始使用。

---

## 5. 🔧 本地模型训练指南 (进阶)
如果您想让模型识别新的垃圾种类，或者提高识别准确率，可以按照以下步骤重新训练模型。

### 5.1 准备数据
1.  进入数据目录：`app/backend-python/training/data_split`。
2.  该目录下有两个子文件夹：
    *   `train`: 用于训练模型。
    *   `val`: 用于验证模型准确率。
3.  在 `train` 和 `val` 中创建以**类别名称**命名的文件夹（例如 `battery`, `apple`）。
4.  将对应的垃圾图片放入这些文件夹中。
    *   *建议*：每个类别至少准备 50 张图片。

### 5.2 开始训练
1.  确保终端位于 `app/backend-python` 目录。
2.  运行训练脚本：
    ```bash
    python training/train.py --epochs 20 --batch_size 16
    ```
    *   `--epochs`: 训练轮数（建议 20-50 轮）。
    *   `--batch_size`: 每次处理的图片数量（显存小请设为 8 或 16）。

3.  **等待训练完成**：
    *   脚本会自动保存验证准确率最高的模型。
    *   训练结束后，新模型会保存在 `training/models/waste_classifier.pt`。

### 5.3 部署新模型
训练完成后，需要将新模型应用到后端服务中。

1.  **自动部署**（推荐）：
    如果您在训练脚本中没有修改输出路径，可以手动复制：
    ```bash
    # Windows 命令
    copy /Y training\models\waste_classifier.pt models\waste_classifier.pt
    copy /Y training\models\labels.json models\labels.json
    ```

2.  **重启后端**：
    关闭并重新运行 `python main.py`，系统将自动加载新模型。

---

## 6. 常见问题 (FAQ)

**Q: 识别结果总是显示 "Unknown"？**
A: 请检查 `dataset_mapping.py`，确保您的训练类别名称（英文）已正确映射到中文名称和四大类。

**Q: 训练时提示 "CUDA out of memory"？**
A: 显存不足。请在运行 `train.py` 时减小 batch size，例如：`--batch_size 8`。

**Q: 如何切换回云端大模型？**
A: 在网页右上角的下拉菜单中选择 "阿里云 Qwen" 即可（需在 `.env` 或环境变量中配置 `DASHSCOPE_API_KEY`）。


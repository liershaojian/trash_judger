"""
æœ¬åœ°æ¨¡å‹æ¨ç†æœåŠ¡
ä½¿ç”¨é¢„è®­ç»ƒçš„ MobileNetV3 è¿›è¡Œåƒåœ¾å¤šåˆ†ç±»
æ”¯æŒ CPU å’Œ GPU æ¨ç†

åˆ†ç±»ä½“ç³»ï¼š
- ç»†åˆ†ç±»ï¼š12+ ç§å¸¸è§åƒåœ¾ç±»å‹
- æ±‡æ€»åˆ°å››å¤§ç±»ï¼šå¯å›æ”¶ç‰©ã€æœ‰å®³åƒåœ¾ã€å¨ä½™åƒåœ¾ã€å…¶ä»–åƒåœ¾
"""

import os
import json
import base64
import io
from typing import Dict, Any, Optional, List
from PIL import Image
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from .dataset_mapping import get_mapped_info

# æ¨¡å‹æ–‡ä»¶è·¯å¾„
MODEL_DIR = os.path.join(os.path.dirname(__file__), '..', 'models')
MODEL_PATH = os.path.join(MODEL_DIR, 'waste_classifier.pt')
LABELS_PATH = os.path.join(MODEL_DIR, 'labels.json')




class WasteClassifier:
    """æœ¬åœ°åƒåœ¾å¤šåˆ†ç±»æ¨¡å‹ - MobileNetV3-Large"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.labels = None
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹å’Œæ ‡ç­¾"""
        try:
            # åŠ è½½æ ‡ç­¾
            if os.path.exists(LABELS_PATH):
                with open(LABELS_PATH, 'r', encoding='utf-8') as f:
                    self.labels = json.load(f)
            else:
                # ä½¿ç”¨é»˜è®¤æ ‡ç­¾ (å¦‚æœ labels.json ä¸å­˜åœ¨)
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å†ç¡¬ç¼–ç  DEFAULT_LABELSï¼Œè€Œæ˜¯ä¾èµ–æ¨¡å‹è¾“å‡ºçš„ç´¢å¼•
                # ä½†ä¸ºäº†å…¼å®¹ï¼Œå¦‚æœçœŸçš„æ²¡æœ‰ labels.jsonï¼Œæˆ‘ä»¬è¿˜æ˜¯éœ€è¦ä¸€ä¸ªé»˜è®¤åˆ—è¡¨
                # æš‚æ—¶ä¿ç•™ä¸€ä¸ªæœ€å°é›†ï¼Œä½†å¼ºçƒˆå»ºè®®ç”¨æˆ·è®­ç»ƒåç”Ÿæˆ labels.json
                self.labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']
            
            num_classes = len(self.labels)
            
            # åŠ è½½æ¨¡å‹
            if os.path.exists(MODEL_PATH):
                # åŠ è½½è‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹
                checkpoint = torch.load(MODEL_PATH, map_location=self.device, weights_only=False)
                
                # åˆ›å»º MobileNetV3-Large æ¨¡å‹
                from torchvision.models import mobilenet_v3_large
                self.model = mobilenet_v3_large(weights=None)
                
                # ä¿®æ”¹åˆ†ç±»å¤´
                self.model.classifier[-1] = nn.Linear(
                    self.model.classifier[-1].in_features, 
                    num_classes
                )
                
                # åŠ è½½æƒé‡
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                    if 'labels' in checkpoint:
                        self.labels = checkpoint['labels']
                else:
                    self.model.load_state_dict(checkpoint)
                    
                print(f"[Local Model] âœ… å·²åŠ è½½è‡ªå®šä¹‰æ¨¡å‹: {MODEL_PATH}")
            else:
                # ä½¿ç”¨é¢„è®­ç»ƒçš„ MobileNetV3-Large
                from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights
                self.model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)
                
                # ä¿®æ”¹åˆ†ç±»å¤´
                self.model.classifier[-1] = nn.Linear(
                    self.model.classifier[-1].in_features,
                    num_classes
                )
                
                print(f"[Local Model] âš ï¸ ä½¿ç”¨ MobileNetV3-Large é¢„è®­ç»ƒæƒé‡ï¼ˆæœªé’ˆå¯¹åƒåœ¾åˆ†ç±»å¾®è°ƒï¼‰")
                print(f"[Local Model] è¯·è¿è¡Œ python download_model.py ä¸‹è½½ä¸“ç”¨æƒé‡")
            
            self.model.to(self.device)
            self.model.eval()
            print(f"[Local Model] ğŸš€ æ¨¡å‹: MobileNetV3-Large (5.4M å‚æ•°)")
            print(f"[Local Model] è¿è¡Œè®¾å¤‡: {self.device}")
            print(f"[Local Model] åˆ†ç±»æ•°é‡: {num_classes} ç±»")
            print(f"[Local Model] ç±»åˆ«åˆ—è¡¨: {self.labels}")
            
        except Exception as e:
            print(f"[Local Model] âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.model = None
    
    def predict(self, image: Image.Image, top_k: int = 3) -> Dict[str, Any]:
        """
        å¯¹å›¾ç‰‡è¿›è¡Œå¤šåˆ†ç±»é¢„æµ‹
        
        Args:
            image: PIL å›¾ç‰‡
            top_k: è¿”å›ç½®ä¿¡åº¦æœ€é«˜çš„ k ä¸ªç»“æœ
        
        Returns:
            åŒ…å« top_k é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        if self.model is None:
            raise Exception("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
        
        # é¢„å¤„ç†
        img_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(img_tensor)
            probs = torch.softmax(outputs, dim=1)
            
            # è·å– top_k ç»“æœ
            top_probs, top_indices = torch.topk(probs, min(top_k, len(self.labels)), dim=1)
        
        # æ„å»ºç»“æœ
        predictions = []
        for i in range(top_probs.size(1)):
            idx = top_indices[0][i].item()
            prob = top_probs[0][i].item()
            label = self.labels[idx] if idx < len(self.labels) else 'trash'
            
            # ä½¿ç”¨æ–°çš„æ˜ å°„é€»è¾‘
            chinese_name, category = get_mapped_info(label)
            
            predictions.append({
                'label': label,
                'label_cn': chinese_name,
                'category': category,
                'confidence': prob
            })
        
        # ä¸»é¢„æµ‹ç»“æœ
        top1 = predictions[0]
        
        return {
            'top1': top1,
            'top_k': predictions,
            'all_probs': {self.labels[i]: probs[0][i].item() for i in range(len(self.labels))}
        }

    def _get_disposal_tips(self, category):
        """è·å–æŠ•æ”¾å»ºè®®"""
        tips = {
            'Recyclable': [
                'è¯·æŠ•æ”¾è‡³è“è‰²å¯å›æ”¶ç‰©åƒåœ¾æ¡¶',
                'ä¿æŒç‰©å“å¹²ç‡¥æ¸…æ´',
                'çº¸ç±»è¯·æŠ˜å æ•´é½ï¼Œå¡‘æ–™ç“¶è¯·å‹æ‰',
                'ç»ç’ƒåˆ¶å“è¯·æ³¨æ„é˜²ç¢'
            ],
            'Hazardous': [
                'è¯·æŠ•æ”¾è‡³çº¢è‰²æœ‰å®³åƒåœ¾æ¡¶',
                'ç”µæ± ã€ç¯æ³¡ç­‰è¯·è½»æ‹¿è½»æ”¾',
                'è¯å“è¯·ä¿ç•™åŸåŒ…è£…',
                'åˆ‡å‹¿ä¸å…¶ä»–åƒåœ¾æ··åˆ'
            ],
            'Wet': [
                'è¯·æŠ•æ”¾è‡³ç»¿è‰²å¨ä½™åƒåœ¾æ¡¶',
                'æ²¥å¹²æ°´åˆ†åæŠ•æ”¾',
                'å»é™¤åŒ…è£…è¢‹ã€ç‰™ç­¾ç­‰æ‚ç‰©',
                'å¤§éª¨å¤´å±äºå¹²åƒåœ¾'
            ],
            'Dry': [
                'è¯·æŠ•æ”¾è‡³ç°è‰²å…¶ä»–åƒåœ¾æ¡¶',
                'å°½é‡æ²¥å¹²æ°´åˆ†',
                'éš¾ä»¥è¾¨åˆ«çš„åƒåœ¾å¯æŠ•æ”¾æ­¤ç±»',
                'æ³¨æ„ä¸è¦æ··å…¥æœ‰å®³åƒåœ¾'
            ],
            'Unknown': [
                'å»ºè®®å’¨è¯¢å½“åœ°åƒåœ¾åˆ†ç±»æŒ‡å—',
                'æˆ–ä½¿ç”¨åœ¨çº¿AIæ¨¡å‹è¿›è¡Œè¯†åˆ«'
            ]
        }
        return tips.get(category, tips['Unknown'])


# å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_classifier_instance: Optional[WasteClassifier] = None


def get_classifier() -> WasteClassifier:
    """è·å–åˆ†ç±»å™¨å•ä¾‹"""
    global _classifier_instance
    if _classifier_instance is None:
        _classifier_instance = WasteClassifier()
    return _classifier_instance


def analyze_waste_local(input_data: str, is_image: bool = True) -> Dict[str, Any]:
    """
    æœ¬åœ°æ¨¡å‹æ¨ç†å…¥å£ï¼ˆå¤šåˆ†ç±»ï¼‰
    
    Args:
        input_data: Base64 å›¾ç‰‡æ•°æ® æˆ– æ–‡æœ¬æè¿°
        is_image: æ˜¯å¦ä¸ºå›¾ç‰‡è¾“å…¥
    
    Returns:
        åˆ†ç±»ç»“æœå­—å…¸ï¼ŒåŒ…å«ç»†åˆ†ç±»å’Œå››å¤§ç±»
    """
    classifier = get_classifier()
    
    if is_image:
        # è§£ç  Base64 å›¾ç‰‡
        try:
            image_bytes = base64.b64decode(input_data)
            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        except Exception as e:
            return {
                'itemName': 'å›¾ç‰‡è§£æå¤±è´¥',
                'category': 'Unknown',
                'confidence': 0,
                'explanation': f'æ— æ³•è§£æå›¾ç‰‡æ•°æ®: {str(e)}',
                'disposalTips': ['å»ºè®®å’¨è¯¢å½“åœ°åƒåœ¾åˆ†ç±»æŒ‡å—']
            }
        
        # è¿›è¡Œé¢„æµ‹
        try:
            result = classifier.predict(image, top_k=3)
            
            top1 = result['top1']
            top_k = result['top_k']
            
            category = top1['category']
            confidence = top1['confidence']
            item_name = top1['label_cn']
            raw_label = top1['label']
            
            # ç”Ÿæˆè§£é‡Šï¼ˆåŒ…å« top-3 ç»“æœï¼‰
            # é‡æ–°è·å–ä¸­æ–‡ç±»åˆ«åç§°
            category_cn_map = {
                'Recyclable': 'å¯å›æ”¶ç‰©',
                'Hazardous': 'æœ‰å®³åƒåœ¾',
                'Wet': 'å¨ä½™åƒåœ¾',
                'Dry': 'å…¶ä»–åƒåœ¾',
                'Unknown': 'æœªçŸ¥ç±»åˆ«'
            }
            category_cn_text = category_cn_map.get(category, 'æœªçŸ¥ç±»åˆ«')
            
            explanation = f"ç»æœ¬åœ°AIæ¨¡å‹åˆ†æï¼Œè¯¥ç‰©å“æœ€å¯èƒ½æ˜¯ã€Œ{item_name}ã€ï¼Œå±äº{category_cn_text}ã€‚"
            
            if len(top_k) > 1:
                other_preds = [f"{p['label_cn']}({p['confidence']*100:.1f}%)" for p in top_k[1:]]
                explanation += f"\nå…¶ä»–å¯èƒ½ï¼š{', '.join(other_preds)}"
            
            if confidence < 0.6:
                explanation += "\nâš ï¸ ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨åœ¨çº¿å¤§æ¨¡å‹è¿›è¡ŒäºŒæ¬¡ç¡®è®¤ã€‚"
            
            return {
                'itemName': item_name,
                'category': category,
                'confidence': round(confidence, 3),
                'explanation': explanation,
                'explanation': explanation,
                # é‡æ–°å®šä¹‰ DISPOSAL_TIPS (å› ä¸ºä¹‹å‰åˆ é™¤äº†)
                'disposalTips': classifier._get_disposal_tips(category),
                'modelType': 'local',
                'rawLabel': raw_label,
                # é¢å¤–è¿”å›å¤šåˆ†ç±»ç»“æœä¾›å‰ç«¯å±•ç¤º
                'multiClassResults': [
                    {
                        'name': p['label_cn'],
                        'category': p['category'],
                        'confidence': round(p['confidence'], 3)
                    }
                    for p in top_k
                ]
            }
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                'itemName': 'è¯†åˆ«å¤±è´¥',
                'category': 'Unknown', 
                'confidence': 0,
                'explanation': f'æœ¬åœ°æ¨¡å‹æ¨ç†å‡ºé”™: {str(e)}',
                'disposalTips': ['å»ºè®®å’¨è¯¢å½“åœ°åƒåœ¾åˆ†ç±»æŒ‡å—']
            }
    else:
        # æ–‡æœ¬è¾“å…¥ - æœ¬åœ°æ¨¡å‹ä¸æ”¯æŒ
        return {
            'itemName': input_data,
            'category': 'Unknown',
            'confidence': 0,
            'explanation': 'æœ¬åœ°æ¨¡å‹ä»…æ”¯æŒå›¾ç‰‡è¯†åˆ«ï¼Œæ–‡æœ¬æŸ¥è¯¢è¯·ä½¿ç”¨åœ¨çº¿æ¨¡å‹ã€‚',
            'disposalTips': ['å»ºè®®åˆ‡æ¢åˆ°åœ¨çº¿æ¨¡å‹è¿›è¡Œæ–‡æœ¬æŸ¥è¯¢']
        }


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    print("=" * 50)
    print("æµ‹è¯•æœ¬åœ°å¤šåˆ†ç±»æ¨¡å‹æœåŠ¡")
    print("=" * 50)
    classifier = get_classifier()
    print(f"\næ¨¡å‹åŠ è½½çŠ¶æ€: {'âœ… æˆåŠŸ' if classifier.model else 'âŒ å¤±è´¥'}")
    print(f"æ”¯æŒç±»åˆ«æ•°: {len(classifier.labels) if classifier.labels else 0}")
    print(f"ç±»åˆ«åˆ—è¡¨: {classifier.labels}")
